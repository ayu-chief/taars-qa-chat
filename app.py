import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util

st.set_page_config(page_title="ã€TAARSã€‘FAQæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ", layout="wide")
st.title("ã€TAARSã€‘FAQæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ")
st.markdown("è³ªå•ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€éå»ã®FAQã‹ã‚‰è¿‘ã„ã‚‚ã®ã‚’ææ¡ˆã—ã¾ã™ã€‚")

# å…¥åŠ›ä¾‹ï¼ˆè¡Œé–“ã‚’è©°ã‚ã¦è¡¨ç¤ºï¼‰
st.markdown("""
<style>
ul.input-examples { margin-top: 0.2rem; margin-bottom: 1rem; line-height: 1.2; padding-left: 1.2rem; }
div.block-container label { margin-bottom: 0.2rem !important; } /* ãƒ©ãƒ™ãƒ«ä¸‹ã®ä½™ç™½ã‚’è©°ã‚ã‚‹ */
</style>
ğŸ’¡ **å…¥åŠ›ä¾‹**ï¼š
<ul class="input-examples">
<li>ãƒ­ã‚°ã‚¤ãƒ³ã§ããªã„</li>
<li>æ”¯æ‰•ã„æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„</li>
<li>å¥‘ç´„ç”³è«‹ã«ã¤ã„ã¦</li>
</ul>
""", unsafe_allow_html=True)

# å¼·èª¿ã•ã‚ŒãŸå…¥åŠ›æ¬„ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä½™ç™½è©°ã‚æ¸ˆï¼‰
st.markdown("### â“ **è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„**")

# åˆæœŸè¡¨ç¤ºä»¶æ•°ã‚’ç®¡ç†
if "visible_count" not in st.session_state:
    st.session_state.visible_count = 10

@st.cache_data
def load_data():
    return pd.read_csv("qa_data.csv", encoding="utf-8")

@st.cache_resource
def load_model_and_embeddings(df):
    model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    embeddings = model.encode(df["question"].tolist(), convert_to_tensor=True)
    return model, embeddings

def format_conversation(text):
    # ã‚µãƒãƒ¼ãƒˆ/ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚¢ã‚¤ã‚³ãƒ³ä»˜ãã«æ•´å½¢
    lines = text.splitlines()
    formatted_lines = []
    for line in lines:
        if "[ã‚µãƒãƒ¼ãƒˆ]" in line:
            line = line.replace("[ã‚µãƒãƒ¼ãƒˆ]", "ğŸ’¬ **ã‚µãƒãƒ¼ãƒˆï¼š**")
        elif "[ãƒ¦ãƒ¼ã‚¶ãƒ¼]" in line:
            line = line.replace("[ãƒ¦ãƒ¼ã‚¶ãƒ¼]", "ğŸ‘¤ **ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼š**")
        formatted_lines.append(line)
    return "\n".join(formatted_lines)

# ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
df = load_data()
model, corpus_embeddings = load_model_and_embeddings(df)

# å…¥åŠ›æ¬„
user_input = st.text_input("", "")

if user_input:
    with st.spinner("æ¤œç´¢ä¸­..."):
        query_embedding = model.encode(user_input, convert_to_tensor=True)
        results = util.semantic_search(query_embedding, corpus_embeddings, top_k=len(df))[0]
        filtered_hits = [hit for hit in results if hit["score"] >= 0.5]
        num_hits = len(filtered_hits)

        if num_hits == 0:
            st.warning("è©²å½“ã™ã‚‹QAãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†å°‘ã—å…·ä½“çš„ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.success(f"{num_hits} ä»¶ã®çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
            if num_hits > 10:
                st.info("çµæœãŒå¤šã„ãŸã‚ã€è³ªå•ã‚’ã•ã‚‰ã«å…·ä½“çš„ã«ã™ã‚‹ã¨çµã‚Šè¾¼ã¿ã‚„ã™ããªã‚Šã¾ã™ã€‚")

            st.markdown("### ğŸ” é¡ä¼¼ã™ã‚‹QAï¼š")
            st.info("ğŸ’¬ ã¯ã‚µãƒãƒ¼ãƒˆã€ğŸ‘¤ ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’è¡¨ã—ã¦ã„ã¾ã™ã€‚")

            for hit in filtered_hits[:st.session_state.visible_count]:
                row = df.iloc[hit["corpus_id"]]
                st.markdown(f"**{row['question']}**")
                with st.expander("â–¶ å›ç­”ã‚’è¦‹ã‚‹"):
                    formatted = format_conversation(str(row['answer']))
                    st.markdown(formatted.replace("\n", "  \n"))
                st.markdown("---")

            if st.session_state.visible_count < num_hits:
                if st.button("ğŸ”½ ã‚‚ã£ã¨è¡¨ç¤ºã™ã‚‹"):
                    st.session_state.visible_count += 10
                    st.rerun()
else:
    st.session_state.visible_count = 10
