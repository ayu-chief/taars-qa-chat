
import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util

st.set_page_config(page_title="ã€TAARSã€‘FAQæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ", layout="wide")
st.title("ã€TAARSã€‘FAQæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ")
st.markdown("è³ªå•ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€éå»ã®FAQã‹ã‚‰è¿‘ã„ã‚‚ã®ã‚’ææ¡ˆã—ã¾ã™ã€‚")

with st.expander("ğŸ’¡ å…¥åŠ›ä¾‹ï¼ˆã‚¯ãƒªãƒƒã‚¯ã—ã¦è¡¨ç¤ºï¼‰"):
    st.markdown("- ä¾‹1ï¼šãƒ­ã‚°ã‚¤ãƒ³ã§ããªã„\n- ä¾‹2ï¼šæ”¯æ‰•ã„æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„\n- ä¾‹3ï¼šå¥‘ç´„ç”³è«‹ã«ã¤ã„ã¦")

@st.cache_data
def load_data():
    return pd.read_csv("qa_data.csv", encoding="utf-8")

@st.cache_resource
def load_model_and_embeddings(df):
    model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    embeddings = model.encode(df["question"].tolist(), convert_to_tensor=True)
    return model, embeddings

df = load_data()
model, corpus_embeddings = load_model_and_embeddings(df)

user_input = st.text_input("â“ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "")

if user_input:
    with st.spinner("æ¤œç´¢ä¸­..."):
        query_embedding = model.encode(user_input, convert_to_tensor=True)
        results = util.semantic_search(query_embedding, corpus_embeddings, top_k=len(df))[0]

        # ã‚¹ã‚³ã‚¢ãŒä¸€å®šä»¥ä¸Šï¼ˆ0.5ï¼‰ã ã‘ã‚’æŠ½å‡º
        filtered_hits = [hit for hit in results if hit["score"] >= 0.5]
        num_hits = len(filtered_hits)

        if num_hits == 0:
            st.warning("è©²å½“ã™ã‚‹QAãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†å°‘ã—å…·ä½“çš„ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            if num_hits > 10:
                st.info(f"{num_hits} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚æ¤œç´¢çµæœãŒå¤šã„ãŸã‚ã€è³ªå•å†…å®¹ã‚’ã•ã‚‰ã«è©³ç´°ã«å…¥åŠ›ã™ã‚‹ã“ã¨ã§çµã‚Šè¾¼ã‚ã¾ã™ã€‚")

            st.markdown("### ğŸ” é¡ä¼¼ã™ã‚‹QAï¼š")
            for hit in filtered_hits:
                row = df.iloc[hit["corpus_id"]]
                st.markdown(f"**{row['question']}**")
                with st.expander("â–¶ å›ç­”ã‚’è¦‹ã‚‹"):
                    st.markdown(f"{row['answer']}")
                st.markdown("---")
