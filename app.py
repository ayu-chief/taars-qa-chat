import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer, util
import re

st.set_page_config(page_title="ã€TAARSã€‘FAQæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ", layout="wide")
st.title("ã€TAARSã€‘FAQæ¤œç´¢ãƒãƒ£ãƒƒãƒˆ")
st.markdown("è³ªå•ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€éå»ã®FAQã‹ã‚‰è¿‘ã„ã‚‚ã®ã‚’ææ¡ˆã—ã¾ã™ã€‚")

# å…¥åŠ›ä¾‹ï¼šCSSã§è¡Œé–“ã‚’è©°ã‚ãŸè¡¨ç¤º
st.markdown("""
<style>
ul.input-examples { margin-top: 0.2rem; margin-bottom: 1rem; line-height: 1.2; padding-left: 1.2rem; }
</style>
ğŸ’¡ **å…¥åŠ›ä¾‹**ï¼š
<ul class="input-examples">
<li>ãƒ­ã‚°ã‚¤ãƒ³ã§ããªã„</li>
<li>æ”¯æ‰•ã„æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„</li>
<li>å¥‘ç´„ç”³è«‹ã«ã¤ã„ã¦</li>
</ul>
""", unsafe_allow_html=True)

# å¼·èª¿ã•ã‚ŒãŸå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¦‹å‡ºã—
st.markdown("### â“ **è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„**")

@st.cache_data
def load_data():
    return pd.read_csv("qa_data.csv", encoding="utf-8")

@st.cache_resource
def load_model_and_embeddings(df):
    model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    embeddings = model.encode(df["question"].tolist(), convert_to_tensor=True)
    return model, embeddings

def format_conversation(text):
    # ä¼šè©±é¢¨ã®æ•´å½¢ï¼šã‚µãƒãƒ¼ãƒˆã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã«çµµæ–‡å­—ã¨æ”¹è¡Œã‚’å…¥ã‚Œã‚‹
    lines = text.splitlines()
    formatted_lines = []
    for line in lines:
        if "[ã‚µãƒãƒ¼ãƒˆ]" in line:
            line = line.replace("[ã‚µãƒãƒ¼ãƒˆ]", "ğŸ’¬ **ã‚µãƒãƒ¼ãƒˆï¼š**")
        elif "[ãƒ¦ãƒ¼ã‚¶ãƒ¼]" in line:
            line = line.replace("[ãƒ¦ãƒ¼ã‚¶ãƒ¼]", "ğŸ‘¤ **ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼š**")
        formatted_lines.append(line)
    return "\n".join(formatted_lines)

df = load_data()
model, corpus_embeddings = load_model_and_embeddings(df)

user_input = st.text_input("", "")

if user_input:
    with st.spinner("æ¤œç´¢ä¸­..."):
        query_embedding = model.encode(user_input, convert_to_tensor=True)
        results = util.semantic_search(query_embedding, corpus_embeddings, top_k=len(df))[0]

        filtered_hits = [hit for hit in results if hit["score"] >= 0.5]
        num_hits = len(filtered_hits)

        if num_hits == 0:
            st.warning("è©²å½“ã™ã‚‹QAãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†å°‘ã—å…·ä½“çš„ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            if num_hits > 10:
                st.info(f"{num_hits} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚è³ªå•ã‚’ã‚ˆã‚Šå…·ä½“çš„ã«å…¥åŠ›ã™ã‚‹ã¨ã€çµæœãŒçµã‚Šè¾¼ã¾ã‚Œã¾ã™ã€‚")

            st.markdown("### ğŸ” é¡ä¼¼ã™ã‚‹QAï¼š")
            st.info("ğŸ’¬ ã¯ã‚µãƒãƒ¼ãƒˆã€ğŸ‘¤ ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’è¡¨ã—ã¦ã„ã¾ã™ã€‚")  # â† ã“ã“ãŒå‡¡ä¾‹ã®è¿½åŠ 

            for hit in filtered_hits:
                row = df.iloc[hit["corpus_id"]]
                st.markdown(f"**{row['question']}**")
                with st.expander("â–¶ å›ç­”ã‚’è¦‹ã‚‹"):
                    formatted = format_conversation(str(row['answer']))
                    st.markdown(formatted.replace("\n", "  \n"))
                st.markdown("---")
